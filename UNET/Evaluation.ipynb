{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow_examples.models.pix2pix import pix2pix\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "#model.layers[4].summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayFuncTime=1\n",
    "orgSize = [512,512]\n",
    "processedSize = [224,224]\n",
    "\n",
    "def normalize(input_image, input_mask):\n",
    "    input_image = tf.cast(input_image, tf.float32) / 255\n",
    "    input_mask += 0\n",
    "    print(\"normalize function input_mask:\",input_mask)\n",
    "    return input_image, input_mask\n",
    "\n",
    "image_feature_description = {\n",
    "    'height': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'width': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'depth': tf.io.FixedLenFeature([], tf.int64),\n",
    "    #'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image': tf.io.FixedLenFeature([], tf.string),\n",
    "    'segmentation_mask': tf.io.FixedLenFeature([], tf.string),\n",
    "    'file_name': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "smooth = 1e-15\n",
    "def iou(y_true, y_pred):\n",
    "    def f(y_true, y_pred):\n",
    "        intersection = (y_true * y_pred).sum()\n",
    "        union = y_true.sum() + y_pred.sum() - intersection\n",
    "        x = (intersection + smooth) / (union + smooth)\n",
    "        x = x.astype(np.float32)\n",
    "        return x\n",
    "    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true = tf.keras.layers.Flatten()(y_true)\n",
    "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
    "\n",
    "@tf.function\n",
    "def load_image_train(datapoint):\n",
    "    datapoint = tf.io.parse_single_example(datapoint, image_feature_description)\n",
    "    print(\"load_image_train's datapoint\",datapoint['image'])\n",
    "    height = tf.cast(datapoint['height'], tf.int64)\n",
    "    width = tf.cast(datapoint['width'], tf.int64)\n",
    "    depth = tf.cast(datapoint['depth'], tf.int64)\n",
    "    image = tf.io.decode_raw(datapoint['image'], tf.uint8)\n",
    "    segmentation_mask = tf.io.decode_raw(datapoint['segmentation_mask'], tf.uint8)\n",
    "    image = tf.reshape(image, [height,width,depth])\n",
    "    segmentation_mask = tf.reshape(segmentation_mask, [height,width,1])\n",
    "    print('image:',image)\n",
    "    #_parsed['image'] = image\n",
    "    #_parsed['segmentation_mask'] = segmentation_mask\n",
    "    input_image = image\n",
    "    #input_image = tf.image.resize(image, (processedSize[0], processedSize[1]))\n",
    "    print(\"load_image_train's input_image\",input_image)\n",
    "    input_mask = segmentation_mask\n",
    "    #input_mask = tf.image.resize(segmentation_mask, (processedSize[0], processedSize[1]))\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        input_image = tf.image.flip_left_right(input_image)\n",
    "        input_mask = tf.image.flip_left_right(input_mask)\n",
    "    input_image, input_mask = normalize(input_image, input_mask)\n",
    "    return input_image, input_mask\n",
    "\n",
    "def load_image_test(datapoint):\n",
    "    datapoint = tf.io.parse_single_example(datapoint, image_feature_description)\n",
    "    print(\"load_image_test's datapoint\",datapoint['image'])\n",
    "    height = tf.cast(datapoint['height'], tf.int64)\n",
    "    width = tf.cast(datapoint['width'], tf.int64)\n",
    "    depth = tf.cast(datapoint['depth'], tf.int64)\n",
    "    image = tf.io.decode_raw(datapoint['image'], tf.uint8)\n",
    "    segmentation_mask = tf.io.decode_raw(datapoint['segmentation_mask'], tf.uint8)\n",
    "    image = tf.reshape(image, [height,width,depth])\n",
    "    segmentation_mask = tf.reshape(segmentation_mask, [height,width,1])\n",
    "    print('image:',image)\n",
    "    #_parsed['image'] = image\n",
    "    #_parsed['segmentation_mask'] = segmentation_mask\n",
    "    input_image = tf.image.resize(image, (processedSize[0], processedSize[1]))\n",
    "    print(\"load_image_test's input_image\",input_image)\n",
    "    input_mask = tf.image.resize(segmentation_mask, (processedSize[0], processedSize[1]))\n",
    "    input_image, input_mask = normalize(input_image, input_mask)\n",
    "    return input_image, input_mask\n",
    "\n",
    "\n",
    "\n",
    "###########\n",
    "\n",
    "\n",
    "def display(display_list):\n",
    "  plt.figure(figsize=(15, 15))\n",
    "\n",
    "  title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "  for i in range(len(display_list)):\n",
    "    plt.subplot(1, len(display_list), i+1)\n",
    "    plt.title(title[i])\n",
    "    #print(\"raw {} display list {}\".format(i,display_list[i]))\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "    plt.axis('off')\n",
    "  plt.show()\n",
    "\n",
    "def displayAndSave(display_list):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        #print(\"raw {} display list {}\".format(i,display_list[i]))\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    global displayFuncTime\n",
    "    plt.savefig(\"display-{}\".format(displayFuncTime))\n",
    "    displayFuncTime+=1\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "###############\n",
    "\n",
    "def create_mask(pred_mask):\n",
    "  pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "  pred_mask = pred_mask[..., tf.newaxis]\n",
    "  return pred_mask[0]\n",
    "####################\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "smooth = 1e-15\n",
    "\n",
    "def show_predictions3(dataset=None, num=1,recordValue=False):\n",
    "    if dataset:\n",
    "        loopNum = 0\n",
    "        for image, mask in dataset.take(num):\n",
    "            #loopNum+=1\n",
    "            pred_mask = model.predict(image)\n",
    "            for i in image:\n",
    "                loopNum+=1\n",
    "                _PIL1 = np.array (tf.keras.preprocessing.image.array_to_img(mask[0]))\n",
    "                _PIL2 = np.array (tf.keras.preprocessing.image.array_to_img(create_mask(pred_mask)))\n",
    "                remap1 =  np.interp(_PIL1, (0, 255), (0, 1))\n",
    "                remap2 =  np.interp(_PIL2, (0, 255), (0, 1))\n",
    "                plt.axis('off')\n",
    "                imgplot = plt.imshow(remap1+remap2)\n",
    "                display([image[0], mask[0], create_mask(pred_mask)])\n",
    "                print(loopNum)\n",
    "                print(\"iou value for new dataset:\",iou(remap1,remap2).numpy())\n",
    "                print(\"dice:\",dice_coef(remap1,remap2).numpy())\n",
    "                iouAry.append(iou(remap1,remap2).numpy())\n",
    "                diceAry.append(dice_coef(remap1,remap2).numpy())\n",
    "                \n",
    "                \n",
    "            \n",
    "            \n",
    "            #_NP_ADDED = np.array(_PIL1)+np.array(_PIL2)\n",
    "            #print(\" remap1:\",  remap1)\n",
    "            \n",
    "            #display([image[0], mask[0], create_mask(_NP_ADDED)])\n",
    "            \n",
    "            \n",
    "            \n",
    "    else:\n",
    "        pred_mask = model.predict(sample_image[tf.newaxis, ...])\n",
    "        m = iou(sample_mask, create_mask(pred_mask))\n",
    "        print(\"iou value (sample pic):\",m.numpy())\n",
    "        if recordValue:\n",
    "            displayAndSave([sample_image, sample_mask,create_mask(pred_mask)])\n",
    "            iouHistory.append(m)\n",
    "        else:\n",
    "            display([sample_image, sample_mask,create_mask(pred_mask)])\n",
    "\n",
    "            \n",
    "            \n",
    "def show_predictions4(dataset=None, num=1,recordValue=False):\n",
    "    if dataset:\n",
    "        loopNum = 0\n",
    "        for image, mask in dataset.take(num):\n",
    "            loopNum+=1\n",
    "            pred_mask = model.predict(image)\n",
    "            _PIL1 = np.array( tf.keras.preprocessing.image.array_to_img(mask[0]))\n",
    "            _PIL2 = np.array (tf.keras.preprocessing.image.array_to_img(create_mask(pred_mask)))\n",
    "            remap1 =  np.interp(_PIL1, (0, 255), (0, 1))\n",
    "            remap2 =  np.interp(_PIL2, (0, 255), (0, 1))\n",
    "            #_NP_ADDED = np.array(_PIL1)+np.array(_PIL2)\n",
    "            #print(\" remap1:\",  remap1)\n",
    "            plt.axis('off')\n",
    "            imgplot = plt.imshow(remap1+remap2)\n",
    "            display([image[0], mask[0], create_mask(pred_mask)])\n",
    "            #display([image[0], mask[0], create_mask(_NP_ADDED)])\n",
    "            print(loopNum)\n",
    "            print(\"iou value for new dataset:\",iou(remap1,remap2).numpy())\n",
    "            print(\"dice:\",dice_coef(remap1,remap2).numpy())\n",
    "            iouAry.append(iou(remap1,remap2).numpy())\n",
    "            diceAry.append(dice_coef(remap1,remap2).numpy())\n",
    "            \n",
    "            \n",
    "    else:\n",
    "        pred_mask = model.predict(sample_image[tf.newaxis, ...])\n",
    "        m = iou(sample_mask, create_mask(pred_mask))\n",
    "        print(\"iou value (sample pic):\",m.numpy())\n",
    "        if recordValue:\n",
    "            displayAndSave([sample_image, sample_mask,create_mask(pred_mask)])\n",
    "            iouHistory.append(m)\n",
    "        else:\n",
    "            display([sample_image, sample_mask,create_mask(pred_mask)])\n",
    "#####################################\n",
    "\n",
    "import numpy as np, scipy.stats as st\n",
    "\n",
    "####################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "functional_1 (Functional)       [(None, 112, 112, 64 11557824    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 14, 14, 512)  4425728     functional_1[0][4]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 14, 14, 512)  0           sequential[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 14, 14, 1088) 0           dropout[0][0]                    \n",
      "                                                                 functional_1[0][3]               \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 28, 28, 256)  2507776     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 28, 28, 256)  0           sequential_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 28, 28, 448)  0           dropout_1[0][0]                  \n",
      "                                                                 functional_1[0][2]               \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 56, 56, 128)  516608      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 56, 56, 128)  0           sequential_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 56, 56, 256)  0           dropout_2[0][0]                  \n",
      "                                                                 functional_1[0][1]               \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 112, 112, 64) 147712      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 112, 112, 64) 0           sequential_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 112, 112, 128 0           dropout_3[0][0]                  \n",
      "                                                                 functional_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 224, 224, 2)  2306        concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 19,157,954\n",
      "Trainable params: 19,022,018\n",
      "Non-trainable params: 135,936\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "PATH=os.getcwd()\n",
    "HPath=\"saved_model/\"\n",
    "Mname=\"043_mobileNETv2_dp2_e50_vMarcoTrainVal02052021_unAUG_bce_lr0001\"\n",
    "batch_size=12\n",
    "\n",
    "model = tf.keras.models.load_model(HPath+Mname)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f59f765c1d25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0miouAry\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdiceAry\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdataset_FULL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTFRecordDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdname\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.tfrecords'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mdatasize\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset_FULL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#raw_image_dataset_fullSize = raw_image_dataset_fullSize.shuffle(100)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "#specify the path and filename of the tfrecord dataset file to be loaded for evaluation\n",
    "dname=\"TFrecord/test\"\n",
    "iouAry=[]\n",
    "diceAry=[]\n",
    "dataset_FULL = tf.data.TFRecordDataset(dname+'.tfrecords')\n",
    "datasize =  sum(1 for _ in dataset_FULL)\n",
    "#raw_image_dataset_fullSize = raw_image_dataset_fullSize.shuffle(100)\n",
    "dataset_FULL_m = dataset_FULL.map(load_image_test)\n",
    "dataset_FULL_b = dataset_FULL_m.batch(1)\n",
    "show_predictions4(dataset_FULL_b,datasize)\n",
    "\n",
    "m1 = np.mean(iouAry)\n",
    "s1 = st.sem(iouAry)\n",
    "s = st.t.interval(0.95, len(iouAry)-1, loc=np.mean(iouAry), scale=st.sem(iouAry))\n",
    "m2 = np.mean(diceAry)\n",
    "s2 = st.sem(diceAry)\n",
    "d = st.t.interval(0.95, len(diceAry)-1, loc=np.mean(diceAry), scale=st.sem(diceAry))\n",
    "\n",
    "print(m1)\n",
    "print(s1)\n",
    "print(s)\n",
    "\n",
    "\n",
    "g = open(\"results/\"+Mname+\"/evaluation.txt\", 'a')\n",
    "print(\"evaluation result for {}, which has the size of {}:\" .format(dname, datasize), file=g)\n",
    "print(\"mean IOU: {}\" .format(m1), file=g)\n",
    "print(\"Standard error of mean of IOU: {}\" .format(s1), file=g)\n",
    "print(\"95% confidence interval of IOU is: {}\" .format(s), file=g)\n",
    "print(\"mean dice: {}\" .format(m2), file=g)\n",
    "print(\"Standard error of mean of dice: {}\" .format(s2), file=g)\n",
    "print(\"95% confidence interval of dice is: {}\" .format(d), file=g)\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
